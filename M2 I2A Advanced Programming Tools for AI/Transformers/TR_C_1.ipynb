{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Based on the Huggin Face Course Introduction : https://huggingface.co/\n",
        "# Modified by Mehdi Ammi, Univ. Paris 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformers: Technical Introduction \n",
        "\n",
        "This notebook provides a comprehensive introduction to the Hugging Face Transformers library, focusing on various natural language processing (NLP) tasks using pre-trained language models. Participants will learn how to install and verify the library, utilize pipelines for sentiment analysis, zero-shot classification, text generation, mask filling, named entity recognition (NER), question answering, text summarization, and translation. By the end of this course, learners will be equipped to effectively leverage these pipelines for a wide range of NLP applications, enhancing their skills in modern language processing techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing Required Libraries\n",
        "\n",
        "First, we need to install the `transformers` library. This library is developed by Hugging Face and provides a wide range of pre-trained models for NLP tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWbZLBZTRLuW",
        "outputId": "3a3d5596-bfbb-4cde-8cfc-812991ad491f"
      },
      "outputs": [],
      "source": [
        "# Install the transformers library\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After installing the transformers library, we will check its version to ensure it has been installed correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efoKDRLgRYrc"
      },
      "outputs": [],
      "source": [
        "# Verify the installation of the transformers library\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Working with pipelines\n",
        "\n",
        "The most basic object in the Huggin Face Transformers library is the pipeline() function. \n",
        "\n",
        "There are three main steps involved when you pass some text to a pipeline():\n",
        "\n",
        " - Text preprocessing,\n",
        " - Model prediction,\n",
        " - Output post-processing.\n",
        "\n",
        "We can directly input any text into it and get an intelligible answer.\n",
        "By default, this pipeline selects a particular pretrained model.\n",
        "\n",
        "Let's try to use it !\n",
        "\n",
        "## Sentiment Analysis Pipeline\n",
        "\n",
        "This pipeline is a pre-configured model that can analyze the sentiment of a given text, categorizing it as positive, negative, or neutral.\n",
        "\n",
        "Initialize the sentiment analysis pipeline. This will download the pre-trained model and tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the sentiment analysis pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of texts to analyze\n",
        "texts = [\n",
        "    \"Nice, I've been waiting for a short HuggingFace course my whole life!\",\n",
        "    \"I hate this so much\"\n",
        "]\n",
        "\n",
        "# Analyze the sentiment of each text\n",
        "results = classifier(texts)\n",
        "\n",
        "# Display the results\n",
        "for text, result in zip(texts, results):\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Sentiment: {result['label']}, Score: {result['score']:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "Text: Nice, I've been waiting for a short HuggingFace course my whole life!\n",
        "Sentiment: POSITIVE, Score: 0.9979\n",
        "\n",
        "Text: I hate this so much\n",
        "Sentiment: NEGATIVE, Score: 0.9995"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each result contains:\n",
        "\n",
        "label: The predicted sentiment label (e.g., POSITIVE or NEGATIVE).\n",
        "score: The confidence score of the prediction.\n",
        "Let's break down the results for better understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example analysis\n",
        "example_text = \"Nice, I've been waiting for a short HuggingFace course my whole life!\"\n",
        "example_result = classifier(example_text)[0]\n",
        "\n",
        "# Display the detailed result\n",
        "print(f\"Text: {example_text}\")\n",
        "print(f\"Sentiment: {example_result['label']}, Score: {example_result['score']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "Text: Nice, I've been waiting for a short HuggingFace course my whole life!\n",
        "Sentiment: POSITIVE, Score: 0.9979"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feel free to analyze more texts by modifying the texts list and re-running the analysis cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add more texts to analyze\n",
        "more_texts = [\n",
        "    \"This is the best movie I have ever seen!\",\n",
        "    \"The product quality is terrible and I'm very disappointed.\",\n",
        "    \"I'm feeling great today!\",\n",
        "    \"It's a gloomy and rainy day.\"\n",
        "]\n",
        "\n",
        "# Analyze the sentiment of each text\n",
        "more_results = classifier(more_texts)\n",
        "\n",
        "# Display the results\n",
        "for text, result in zip(more_texts, more_results):\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Sentiment: {result['label']}, Score: {result['score']:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "Text: This is the best movie I have ever seen!\n",
        "Sentiment: POSITIVE, Score: 0.9999\n",
        "\n",
        "Text: The product quality is terrible and I'm very disappointed.\n",
        "Sentiment: NEGATIVE, Score: 0.9998\n",
        "\n",
        "Text: I'm feeling great today!\n",
        "Sentiment: POSITIVE, Score: 0.9999\n",
        "\n",
        "Text: It's a gloomy and rainy day.\n",
        "Sentiment: NEGATIVE, Score: 0.9975"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other pipelines\n",
        "Some of the currently available pipelines are:\n",
        "\n",
        " - feature-extraction\n",
        "- fill-mask\n",
        "- ner (named entity recognition)\n",
        "- question-answering\n",
        "- sentiment-analysis\n",
        "- summarization\n",
        "- text-generation\n",
        "- translation\n",
        "- zero-shot-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zero-shot classification\n",
        "\n",
        "The zero-shot-classification pipeline is very powerful for tasks where we need to classify texts that haven’t been labelled. It returns probability scores for any list of labels you want!\n",
        "It's called zero-shot because you don’t need to fine-tune the model on your data to use it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the Classifier\n",
        "\n",
        "We initialize the classifier using the `pipeline` function and specify `\"zero-shot-classification\"` as the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a zero-shot classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classify a Sample Text\n",
        "\n",
        "We will classify the sample text into one of the candidate labels provided.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample text to classify\n",
        "text = \"This is a short course about the Transformers library\" \n",
        "\n",
        "# List of candidate labels for classification\n",
        "candidate_labels = [\"education\", \"politics\", \"business\"]\n",
        "\n",
        "# Perform zero-shot classification\n",
        "result = classifier(text, candidate_labels=candidate_labels)\n",
        "\n",
        "# Print the result\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "{\n",
        "  'sequence': 'This is a short course about the Transformers library',  # The input text\n",
        "  'labels': ['education', 'business', 'politics'],  # The candidate labels\n",
        "  'scores': [0.7481650114059448, 0.17828474938869476, 0.07355023920536041]  # The confidence scores for each label\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explanation of Results\n",
        "\n",
        "The output is a dictionary containing the input sequence, the list of candidate labels, and the corresponding scores.\n",
        "The scores represent the model's confidence in each label.\n",
        "\n",
        "In this example, the model has determined that \"education\" is the most appropriate label for the input text, with a high confidence score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Further Exploration\n",
        "\n",
        "You can experiment with different texts and sets of candidate labels to see how the model performs. \n",
        "Try classifying the following texts:\n",
        "\n",
        "1. \"The stock market is showing signs of recovery after a steep decline.\"\n",
        "2. \"The new policy aims to improve healthcare accessibility for all citizens.\"\n",
        "\n",
        "Use candidate labels such as `[\"finance\", \"healthcare\", \"politics\"]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"The stock market is showing signs of recovery after a steep decline.\",  # Example text 1\n",
        "    \"The new policy aims to improve healthcare accessibility for all citizens.\"  # Example text 2\n",
        "]\n",
        "\n",
        "# New set of candidate labels\n",
        "candidate_labels = [\"finance\", \"healthcare\", \"politics\"]\n",
        "\n",
        "# Perform zero-shot classification for each text\n",
        "for text in texts:\n",
        "    result = classifier(text, candidate_labels=candidate_labels)  \n",
        "    print(f\"Text: {text}\")  # Print the input text\n",
        "    print(f\"Classification: {result}\\n\")  # Print the classification result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "Text: The stock market is showing signs of recovery after a steep decline.\n",
        "Classification: {'sequence': 'The stock market is showing signs of recovery after a steep decline.', 'labels': ['finance', 'healthcare', 'politics'], 'scores': [0.9854428172111511, 0.007386600133031607, 0.007170595694333315]}\n",
        "\n",
        "Text: The new policy aims to improve healthcare accessibility for all citizens.\n",
        "Classification: {'sequence': 'The new policy aims to improve healthcare accessibility for all citizens.', 'labels': ['healthcare', 'politics', 'finance'], 'scores': [0.9620512127876282, 0.027672864496707916, 0.010275940410792828]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Control\n",
        "\n",
        " - candidate_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text generation\n",
        "\n",
        "The main idea here is that you provide a prompt and the model will auto-complete it by generating the remaining text.\n",
        "\n",
        "Here, we create a text generation pipeline by calling pipeline with the argument \"text-generation\". This pipeline will use a pre-trained model to generate text based on a given prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a text generation pipeline using a pre-trained model\n",
        "generator = pipeline(\"text-generation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we define the prompt that we want to complete using the model. In this case, the prompt is \"In this course, we will teach you how to\".\n",
        "\n",
        "Then, we generate the text by calling the generator with the prompt. We also specify max_length=50 to limit the total length of the output text to 50 tokens, and num_return_sequences=3 to generate three different sequences based on the prompt.\n",
        "\n",
        "Finally, we display the generated text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setting up the prompt\n",
        "prompt = \"In this course, we will teach you how to\"\n",
        "\n",
        "# Generating text with specific control parameters\n",
        "generated_text = generator(prompt, max_length=50, num_return_sequences=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Displaying the generated text\n",
        "for i, text in enumerate(generated_text):\n",
        "    print(f\"Generated Text {i+1}: {text['generated_text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "Generated Text 1: In this course, we will teach you how to create simple software components with advanced principles and develop new ones. The purpose of this course is to provide you with a good understanding of programming by way of programming principles. In the course, you will develop\n",
        "Generated Text 2: In this course, we will teach you how to use the same techniques to control a network of computers, to control a web server operating in the cloud. We will show you how to use your data to build web applications and applications based on the same\n",
        "Generated Text 3: In this course, we will teach you how to build a custom Linux shell by analyzing the following techniques and implementing them in your own shell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Control\n",
        "\n",
        " - max_length: total length of the output text.\n",
        " - num_return_sequences: number of returning sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using any model from the Hub in a pipeline\n",
        "\n",
        "The previous examples used the default model for the task at hand, but you can also choose a particular model from the Hub to use in a pipeline for a specific task — say, text generation.\n",
        "\n",
        "Let’s try the distilgpt2 model : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a text generation pipeline using the 'distilgpt2' model from the Hugging Face Hub\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "# Defining the prompt for text generation\n",
        "prompt = \"In this course, we will teach you how to\"\n",
        "\n",
        "# Generating text with specific parameters\n",
        "# max_length: the total length of the generated text\n",
        "# num_return_sequences: the number of generated sequences\n",
        "generated_text = generator(prompt, max_length=30, num_return_sequences=2)\n",
        "\n",
        "# Displaying the generated text\n",
        "for i, text in enumerate(generated_text):\n",
        "    print(f\"Generated Text {i+1}: {text['generated_text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "Generated Text 1: In this course, we will teach you how to improve your daily routine and take notes. You can also learn to perform a lot of things including meditation\n",
        "Generated Text 2: In this course, we will teach you how to understand a language as a whole and how to create a useful alternative to the language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mask filling\n",
        "\n",
        "The idea of this task is to fill in the blanks in a given text using pre-trained language models.\n",
        "\n",
        "### Creating the Unmasker:\n",
        "\n",
        "This line initializes a pipeline for the fill-mask task. The \"fill-mask\" argument specifies that we want to use a model trained to predict missing words in a sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a pipeline for the fill-mask task\n",
        "unmasker = pipeline(\"fill-mask\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filling the Mask:\n",
        "\n",
        "Here, we use the unmasker to predict the masked word in the sentence. The top_k argument specifies how many of the top predictions we want to display. Here, we request the top 2 predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The '<mask>' token is a placeholder for the word that the model will predict\n",
        "results = unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the results\n",
        "# The results show the top_k predictions the model suggests for the masked word\n",
        "for result in results:\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{'score': 0.19619794189929962, 'token': 30412, 'token_str': ' mathematical', 'sequence': 'This course will teach you all about mathematical models.'}\n",
        "{'score': 0.04052729159593582, 'token': 38163, 'token_str': ' computational', 'sequence': 'This course will teach you all about computational models.'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This loop prints out each prediction result. Each result includes:\n",
        "\n",
        "score: The model's confidence in the prediction.\n",
        "token: The token ID of the predicted word.\n",
        "token_str: The predicted word.\n",
        "sequence: The full sentence with the predicted word filled in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Control \n",
        " - top_k argument: controls how many possibilities you want to be displayed.\n",
        " - <mask>: mask token or special word the model must fills in. It depends on the used model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Named entity recognition (NER)\n",
        "\n",
        "NER is a task where the model has to find which parts of the input text correspond to entities such as persons, locations, or organizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the NER Pipeline:\n",
        "\n",
        "This line initializes a pipeline for the named entity recognition (NER) task. The \"ner\" argument specifies that we want to use a model trained for NER. The grouped_entities=True argument groups together consecutive tokens that are part of the same entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a pipeline for the named entity recognition (NER) task\n",
        "ner = pipeline(\"ner\", grouped_entities=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Identifying Entities:\n",
        "\n",
        "In this line, we use the ner pipeline to identify entities in the given sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the pipeline to identify entities in the given sentence\n",
        "results = ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n",
        "\n",
        "# Display the results\n",
        "# The results show the entities found in the sentence along with their types and positions\n",
        "for result in results:\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "{'entity_group': 'PER', 'score': 0.9981694, 'word': 'Sylvain', 'start': 11, 'end': 18}\n",
        "{'entity_group': 'ORG', 'score': 0.9796019, 'word': 'Hugging Face', 'start': 33, 'end': 45}\n",
        "{'entity_group': 'LOC', 'score': 0.9932106, 'word': 'Brooklyn', 'start': 49, 'end': 57}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This loop prints out each identified entity. Each result includes:\n",
        "\n",
        "- entity_group: The type of entity (e.g., PER for person, ORG for organization, LOC for location).\n",
        "- score: The model's confidence in the prediction.\n",
        "- word: The entity found in the text.\n",
        "- start: The starting position of the entity in the text.\n",
        "- end: The ending position of the entity in the text.\n",
        "\n",
        "In the given example, the model correctly identified:\n",
        "\n",
        " - Sylvain as a person (PER),\n",
        " - Hugging Face as an organization (ORG),\n",
        " - Brooklyn as a location (LOC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Control \n",
        "\n",
        " - grouped_entities=True: regroup together the parts of the sentence that correspond to the same entity (grouping “Hugging” and “Face” as a single organization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question answering\n",
        "\n",
        "The question-answering pipeline answers questions using information from a given context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the Question-Answering Pipeline\n",
        "\n",
        "This line initializes a pipeline for the question-answering task. The \"question-answering\" argument specifies that we want to use a model trained to answer questions based on a given context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a pipeline for the question-answering task\n",
        "question_answerer = pipeline(\"question-answering\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Answering the Question\n",
        "\n",
        "In this block, we use the question_answerer pipeline to answer the question \"Where do I work?\" based on the provided context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the pipeline to answer a question based on the given context\n",
        "result = question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "# The result shows the answer to the question along with additional information\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "{'score': 0.6949766278266907, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This line prints out the result of the question-answering task. The result includes:\n",
        "\n",
        "- score: The model's confidence in the answer.\n",
        "- start: The starting position of the answer in the context.\n",
        "- end: The ending position of the answer in the context.\n",
        "- answer: The extracted answer from the context.\n",
        "\n",
        "\n",
        "In the given example, the model correctly identified the answer to the question \"Where do I work?\" as Hugging Face. The result also provides the confidence score and the positions of the answer within the context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summarization \n",
        "\n",
        "Summarization is the task of reducing a text into a shorter text while keeping all (or most) of the important aspects referenced in the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the Summarization Pipeline\n",
        "\n",
        "This line initializes a pipeline for the summarization task. The \"summarization\" argument specifies that we want to use a model trained to summarize text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a pipeline for the summarization task\n",
        "summarizer = pipeline(\"summarization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summarizing the Text\n",
        "\n",
        "In this block, we use the summarizer pipeline to condense the provided text into a shorter version while keeping the most important information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the pipeline to summarize the given text\n",
        "summary = summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number \n",
        "    of graduates in traditional engineering disciplines such as mechanical, civil, \n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
        "    the premier American universities engineering curricula now concentrate on \n",
        "    and encourage largely the study of engineering science. As a result, there \n",
        "    are declining offerings in engineering subjects dealing with infrastructure, \n",
        "    the environment, and related issues, and greater concentration on high \n",
        "    technology subjects, largely supporting increasingly complex scientific \n",
        "    developments. While the latter is important, it should not be at the expense \n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other \n",
        "    industrial countries in Europe and Asia, continue to encourage and advance \n",
        "    the teaching of engineering. Both China and India, respectively, graduate \n",
        "    six and eight times as many traditional engineers as does the United States. \n",
        "    Other industrial countries at minimum maintain their output, while America \n",
        "    suffers an increasingly serious decline in the number of engineering \n",
        "    graduates and a lack of well-educated engineers.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Display the summary\n",
        "# The summary provides a condensed version of the original text while retaining the most important information\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "[{'summary_text': ' America has changed dramatically during recent years . The number of graduates in traditional engineering disciplines has declined . China and India graduate six and eight times as many traditional engineers as does the United States . Rapidly developing economies such as India and Europe continue to encourage and advance the teaching of engineering .'}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Control\n",
        "\n",
        "Same as text generation:\n",
        "\n",
        " - max_length\n",
        " - min_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Translation\n",
        "\n",
        "For translation, you can use a default model if you provide a language pair in the task name (such as \"translation_en_to_fr\"), but the easiest way is to pick the model you want to use on the Model Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the Translation Pipeline\n",
        "\n",
        "This line initializes a pipeline for the translation task. The \"translation\" argument specifies that we want to use a model trained for translation. The model=\"Helsinki-NLP/opus-mt-fr-en\" argument specifies the specific model to use for translating from French to English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a pipeline for the translation task\n",
        "# Specify the model to be used for translation from French to English\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Translating the Text\n",
        "\n",
        "In this line, we use the translator pipeline to translate the provided French text into English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the pipeline to translate the given text from French to English\n",
        "translation = translator(\"Ce cours est produit par Hugging Face.\")\n",
        "\n",
        "# Display the translation\n",
        "# The translation provides the English version of the original French text\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ">>\n",
        "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Control\n",
        "\n",
        "Same as text generation & summarization:\n",
        "\n",
        "- max_length\n",
        "- min_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercices "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Sentiment Analysis\n",
        "\n",
        " - Analyze the sentiment of the following sentences: \"I am very happy with the service.\" and \"The food was terrible.\"\n",
        " - Add a new sentence to the list: \"I'm feeling neutral about this.\" and analyze its sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Zero-shot Classification\n",
        "\n",
        " - Classify the following text into one of the candidate labels: \"finance\", \"healthcare\", \"politics\": \"The new policy aims to improve healthcare accessibility for all citizens.\"\n",
        " - Change the candidate labels to \"education\", \"entertainment\", \"business\" and classify the same text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Text Generation\n",
        "\n",
        " - Generate text with the prompt \"Artificial intelligence will change the world by\" with a maximum length of 50 tokens.\n",
        " - Change the prompt to \"In the future, we will see advancements in\" and generate text with a maximum length of 30 tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4: Mask Filling\n",
        "\n",
        " - Predict the masked word in the sentence \"Artificial intelligence is the future of <mask>.\"\n",
        " - Change the sentence to \"The development of AI will revolutionize <mask>.\" and predict the masked word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 5: Named Entity Recognition (NER)\n",
        "\n",
        " - Identify entities in the sentence \"Elon Musk founded SpaceX and Tesla.\"\n",
        " - Add a new sentence \"Barack Obama was the 44th President of the United States.\" and identify entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 6: Question Answering\n",
        "\n",
        " - Answer the question \"What is the name of the company?\" given the context \"Amazon is a global company based in Seattle.\"\n",
        " - Change the context to \"Google was founded by Larry Page and Sergey Brin.\" and ask the question \"Who founded Google?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 7: Summarization\n",
        "\n",
        " - Summarize the following text: \"Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns, and make decisions with minimal human intervention.\"\n",
        " - Summarize the following text: \"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data. Like a human, the algorithm learns from examples. While traditional machine learning algorithms are linear, deep learning algorithms are stacked in a hierarchy of increasing complexity and abstraction.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 8: Translation\n",
        "\n",
        " - Translate the sentence \"Bonjour tout le monde.\" from French to English.\n",
        " - Translate the sentence \"La technologie transforme notre monde.\" from French to English."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 9: Comprehensive NLP Task\n",
        "\n",
        "This exercise will combine sentiment analysis, zero-shot classification, and text generation.\n",
        "\n",
        " - Perform sentiment analysis on the following sentences: \"I love the new features of this product.\" and \"This is the worst experience I've ever had.\"\n",
        " - Classify the following text into one of the candidate labels: \"technology\", \"customer service\", \"product quality\": \"The new smartphone has several innovative features that are very user-friendly.\"\n",
        " - Generate text with the prompt \"Based on the customer feedback, we can improve our product by\" with a maximum length of 50 tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 10: Multi-Function NLP Task\n",
        "\n",
        "This exercise will combine named entity recognition (NER), question answering, and text summarization.\n",
        "\n",
        " - Identify entities in the sentence: \"Sundar Pichai is the CEO of Google, which is headquartered in Mountain View, California.\"\n",
        " - Answer the question \"Where is Google headquartered?\" given the context \"Sundar Pichai is the CEO of Google, which is headquartered in Mountain View, California.\"\n",
        " - Summarize the following text: \"Google, a multinational technology company specializing in Internet-related services and products, was founded by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University.\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
